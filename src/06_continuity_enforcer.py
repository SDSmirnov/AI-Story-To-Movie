import argparse
import json
import logging
import os
import time
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from google import genai
from PIL import Image
from threading import Lock

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
TEXT_MODEL = os.getenv('AI_TEXT_MODEL', "gemini-2.5-pro")
IMAGE_MODEL = os.getenv('AI_IMAGE_MODEL', "gemini-3-pro-image-preview")
MAX_WORKERS = int(os.getenv('AI_CONCURRENCY', '5'))

api_key = os.getenv('IMG_AI_API_KEY', '')
if not api_key:
    logger.error("‚ùå –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω API –∫–ª—é—á")
    exit(1)

client = genai.Client(api_key=api_key)

OUTPUT_DIR = Path("cinematic_render")
REF_DIR = Path("ref_thriller")

class RateLimiter:
    def __init__(self, rpm: int):
        self.rpm = rpm
        self.tokens = rpm
        self.max_tokens = rpm
        self.last_update = time.time()
        self.lock = Lock()

    def acquire(self):
        with self.lock:
            now = time.time()
            elapsed = now - self.last_update
            self.tokens = min(self.max_tokens, self.tokens + elapsed * (self.rpm / 60))
            self.last_update = now
            if self.tokens < 1:
                wait_time = (1 - self.tokens) * (60 / self.rpm)
                time.sleep(wait_time)
                self.tokens = 0
            else:
                self.tokens -= 1

limiter = RateLimiter(rpm=20)

def generate_json_with_schema(prompt: str, schema: dict = None):
    limiter.acquire()
    generation_config = {
        "temperature": 0.2, # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
        "response_mime_type": "application/json",
        "response_schema": schema,
        "max_output_tokens": 32000,
    }
    try:
        response = client.models.generate_content(
            model=TEXT_MODEL,
            contents=prompt,
            config=generation_config
        )
        return json.loads(response.text)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ LLM: {e}")
        return None

# --- –°–•–ï–ú–´ ---
UPDATED_REF_SCHEMA = {
    "type": "object",
    "properties": {
        "visual_desc": {"type": "string", "description": "Highly detailed, comprehensive visual description incorporating all new scene details."},
        "video_visual_desc": {"type": "string", "description": "Shorter summary of the updated description."}
    },
    "required": ["visual_desc", "video_visual_desc"]
}

SCENE_REWRITE_SCHEMA = {
    "type": "object",
    "properties": {
        "panels": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "panel_index": {"type": "integer"},
                    "visual_start": {"type": "string"},
                    "visual_end": {"type": "string"}
                },
                "required": ["panel_index", "visual_start", "visual_end"]
            }
        }
    },
    "required": ["panels"]
}

def collect_reference_usage(metadata: dict) -> dict:
    """–°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ –æ–ø–∏—Å–∞–Ω–∏—è –ø–∞–Ω–µ–ª–µ–π, –≥–¥–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –∫–∞–∂–¥—ã–π —Ä–µ—Ñ–µ—Ä–µ–Ω—Å."""
    ref_usage = {}
    for scene in metadata.get('scenes', []):
        for panel in scene.get('panels', []):
            for ref in panel.get('references', []):
                if ref not in ref_usage:
                    ref_usage[ref] = []
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ç–æ–≥–æ, –∫–∞–∫ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
                context = f"Scene {scene['scene_id']}, Panel {panel['panel_index']}: Start: {panel['visual_start']} | End: {panel['visual_end']} | Camera: {panel.get('lights_and_camera', '')}"
                ref_usage[ref].append(context)
    return ref_usage

def enrich_and_regenerate_reference(ref_name: str, usage_contexts: list):
    """–û–±–æ–≥–∞—â–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞ –∏ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É."""
    safe_name = ref_name.replace("/", "-").replace("'", " ").replace('"', '').replace(" ", "_").lower()
    json_path = REF_DIR / f"{safe_name}.json"
    png_path = REF_DIR / f"{safe_name}.png"
    
    if not json_path.exists():
        logger.warning(f"‚ö†Ô∏è  JSON –¥–ª—è {ref_name} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±–æ–≥–∞—â–µ–Ω–∏–µ.")
        return

    with open(json_path, 'r', encoding='utf-8') as f:
        ref_data = json.load(f)

    logger.info(f"üîç –û–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–µ–π –¥–ª—è: {ref_name} (–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –≤ {len(usage_contexts)} –ø–∞–Ω–µ–ª—è—Ö)")

    # 1. –ó–∞—Å—Ç–∞–≤–ª—è–µ–º LLM —Å–ª–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å –Ω–æ–≤—ã–º–∏ –¥–µ—Ç–∞–ª—è–º–∏
    prompt = f"""
    You are a Lead Production Designer.
    We have an original visual description for the entity "{ref_name}":
    <ORIGINAL_DESC>
    {ref_data['visual_desc']}
    </ORIGINAL_DESC>

    However, the storyboard artist added specific new details in various scenes. 
    Here is how "{ref_name}" is actually described in the scenes:
    <SCENE_USAGES>
    {chr(10).join(usage_contexts[:20])} # limit to avoid context overload
    </SCENE_USAGES>

    TASK: 
    Merge the ORIGINAL_DESC with all specific physical details invented in the SCENE_USAGES (e.g., specific desk color, exact props, specific lighting fixtures, specific clothing details). 
    Do NOT include actions or temporary states. ONLY permanent visual design features.
    Generate a massive, highly detailed visual description that perfectly aligns with what the scenes require.
    """

    updated_desc = generate_json_with_schema(prompt, UPDATED_REF_SCHEMA)
    
    if updated_desc:
        ref_data['visual_desc'] = updated_desc['visual_desc']
        ref_data['video_visual_desc'] = updated_desc['video_visual_desc']
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π JSON
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(ref_data, f, ensure_ascii=False, indent=2)

        # 2. –ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º PNG
        logger.info(f"  üé® –ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è PNG –¥–ª—è {ref_name} —Å –Ω–æ–≤—ã–º–∏ –¥–µ—Ç–∞–ª—è–º–∏...")
        ref_prompt = f"CINEMATIC REFERENCE FOR {ref_data.get('type', 'Entity')}: {ref_name}. {ref_data['visual_desc']}. Close-up, neutral expression, uniform lighting, 8k."
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å style_reference, –ø–æ–¥–≥—Ä—É–∂–∞–µ–º –µ–≥–æ
        if ref_data.get('style_reference') and ref_data['style_reference'] != ref_name:
            style_safe = ref_data['style_reference'].replace("/", "-").replace(" ", "_").lower()
            style_path = REF_DIR / f"{style_safe}.png"
            if style_path.exists():
                img = Image.open(style_path)
                ref_prompt = [f"## Visual Style reference for {ref_data['style_reference']}", img, ref_prompt]

        try:
            limiter.acquire()
            resp = client.models.generate_content(
                model=IMAGE_MODEL, contents=ref_prompt,
                config={'response_modalities': ['Image'], 'image_config': {'aspect_ratio': '3:4', 'image_size': '1K'}}
            )
            if resp.parts[0].inline_data:
                resp.parts[0].as_image().save(png_path)
                logger.info(f"  ‚úÖ {ref_name} —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω.")
        except Exception as e:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –¥–ª—è {ref_name}: {e}")

def align_scene_prompts(scene: dict, all_refs_data: dict) -> dict:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –ø—Ä–∞–≤–∏—Ç –ø–∞–Ω–µ–ª—å —Å—Ü–µ–Ω—ã, —á—Ç–æ–±—ã –æ–Ω–∞ –Ω–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–ª–∞ —Ñ–∏–Ω–∞–ª—å–Ω—ã–º —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞–º."""
    logger.info(f"üé¨ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –°—Ü–µ–Ω—ã {scene['scene_id']}...")
    
    scene_refs = set()
    for panel in scene['panels']:
        scene_refs.update(panel.get('references', []))
    
    if not scene_refs:
        return scene

    ref_context = {}
    for ref in scene_refs:
        safe_name = ref.replace("/", "-").replace(" ", "_").lower()
        if safe_name in all_refs_data:
            ref_context[ref] = all_refs_data[safe_name]['video_visual_desc']

    prompt = f"""
    You are a Script Supervisor enforcing Visual Continuity.
    
    Here is the FINAL, APPROVED visual design for the entities in this scene:
    <APPROVED_REFERENCES>
    {json.dumps(ref_context, indent=2)}
    </APPROVED_REFERENCES>

    Here is the current scene data:
    <CURRENT_SCENE>
    {json.dumps(scene['panels'], indent=2)}
    </CURRENT_SCENE>

    TASK:
    Rewrite 'visual_start' and 'visual_end' for each panel ONLY IF they contradict the APPROVED_REFERENCES. 
    Ensure that colors, props, and materials mentioned in the scene exactly match the approved references.
    Do not change the action or cinematography, only enforce physical prop/character consistency.
    Return the full list of panels with your adjusted visual_start and visual_end.
    """

    aligned_data = generate_json_with_schema(prompt, SCENE_REWRITE_SCHEMA)
    
    if aligned_data and 'panels' in aligned_data:
        aligned_map = {p['panel_index']: p for p in aligned_data['panels']}
        for panel in scene['panels']:
            if panel['panel_index'] in aligned_map:
                panel['visual_start'] = aligned_map[panel['panel_index']]['visual_start']
                panel['visual_end'] = aligned_map[panel['panel_index']]['visual_end']
                
    return scene

def main():
    metadata_path = OUTPUT_DIR / "animation_metadata.json"
    if not metadata_path.exists():
        logger.error("‚ùå animation_metadata.json –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ 01_cinematic_preroll.py")
        return

    with open(metadata_path, 'r', encoding='utf-8') as f:
        metadata = json.load(f)

    # –®–ê–ì 1: –ê–≥—Ä–µ–≥–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤
    logger.info("=== –®–ê–ì 1: –ê–ù–ê–õ–ò–ó –î–†–ò–§–¢–ê –î–ï–¢–ê–õ–ï–ô ===")
    ref_usage = collect_reference_usage(metadata)
    
    # –®–ê–ì 2: –û–±–æ–≥–∞—â–µ–Ω–∏–µ –∏ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤
    logger.info("=== –®–ê–ì 2: –û–ë–ù–û–í–õ–ï–ù–ò–ï –†–ï–§–ï–†–ï–ù–°–û–í ===")
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        for ref_name, usages in ref_usage.items():
            executor.submit(enrich_and_regenerate_reference, ref_name, usages)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å—ã –≤ –ø–∞–º—è—Ç—å
    all_refs_data = {}
    for ref_file in REF_DIR.glob("*.json"):
        all_refs_data[ref_file.stem] = json.loads(ref_file.read_text(encoding='utf-8'))

    # –®–ê–ì 3: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏–π —Å—Ü–µ–Ω
    logger.info("=== –®–ê–ì 3: –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø –°–¶–ï–ù ===")
    aligned_scenes = []
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        results = executor.map(lambda s: align_scene_prompts(s, all_refs_data), metadata['scenes'])
        aligned_scenes = list(results)

    metadata['scenes'] = aligned_scenes

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π, —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã–π –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    out_path = OUTPUT_DIR / "animation_metadata_consistent.json"
    with open(out_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
        
    logger.info(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {out_path}")
    logger.info("–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–æ—Ç —Ñ–∞–π–ª –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–∞–Ω–µ–ª–µ–π.")

if __name__ == "__main__":
    main()
